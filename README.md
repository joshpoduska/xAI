# Explainable AI

![img](scratch/blackbox.png)

Model interpretability is a seminal topic in the field of data science. 
The field is moving quickly. Practitioners can leverage a range of tools to provide 
explainability to their models from traditional approaches to the latest in deep neural 
network explainers.

## Project Contents

This project contains starter code for a few of these approaches and some educational material on xAI.

* [SHAP_and_LIME.ipynb](SHAP_and_LIME.ipynb)  -  a how-to notebook
* [rtemis.R](rtemis.R)  -  a how-to R file
* [traditional_methods.ipynb](traditional_methods.ipynb)  -  a how-to notebook
* [Navigating Interpretable and Predictive Models.pdf](Navigating+Interpretable+and+Predictive+Models.pdf)  -  slides from the Domino tech talk on xAI which includes many links to further research

## Suggested Actions

* Explore the SHAP_and_LIME.ipynb notebook

## Reference Material

* Learn more about xAI by browsing the instructional pdf

## Prerequisites

This project uses standard python libraries and any base Domino image should work well. The additional Python libraries needed are *shap*, *lime*, and *pycebox*. 

There are several additional R libraries needed to run *rtemis*. This library changes frequently, sometimes breaking dependencies. See the R script included in this project for details.
